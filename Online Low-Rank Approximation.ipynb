{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Rank Approximation (PCA)\n",
    "\n",
    "- Many data sets come in the form of a matrix.\n",
    "- Think of $A$ as a stack of $n$ data points in $\\mathbb{R}^d$.\n",
    "- For example, $A$ can be a customer-product matrix, where each entry $A_{ij}$ refers to the number of times customer $i$ purchased item $j$.\n",
    "- A data matrix $A$ is typically well-approximated by a low rank matrix, that is\n",
    "$$\n",
    "A = A_{approx} + E,\n",
    "$$\n",
    "where $rank(A_{approx})=k$ and $\\|E\\|_F$ is close to zero. (The *Frobenius norm* $\\|\\cdot\\|_F$ is computed by summing up the square of its entries).\n",
    "- Compare to $A$, $A_{approx}$ is easier to store and its values are more interpretable.\n",
    "\n",
    "**Problem:** Given a matrix $A\\in\\mathbb{R}^{n\\times d}$ and a $k\\ll d<n$, find a $k$-dimensional subspace $S$ such that $\\|A - \\Pi_SA\\|_F^2$ is minimized.\n",
    "\n",
    "**Traiditional solution:** Truncated singular value decomposition (Truncated SVD)\n",
    "Any matrix $A$ can be written as $A = U\\cdot \\Sigma \\cdot V$, where\n",
    "- Matrix $U$ has orthonormal column vectors\n",
    "- Matrix $\\Sigma$ is a diagonal matrix with non-increasing positive entries down the diagonal\n",
    "- Matrix $V$ has othonormal row vectors\n",
    "\n",
    "The best rank-$k$ approximation to $A$ is $A_k=U_k\\cdot\\Sigma_k\\cdot V_k$, where\n",
    "- Matrix $U_k$ consists of the first $k$ columns of $U$.\n",
    "- Matrix $V_k$ consists of the first $k$ rows of $V$. (They are called the **top $k$ principal components**.)\n",
    "- Matrix $\\Sigma_k$ consists of the first $k$ diagonal elements of $\\Sigma$.\n",
    "\n",
    "Equivalently speaking, $A_k = argmin_{rank(B)=k}\\|A - B\\|_F$. The **main problem with the SVD approch** is its high computational complexity ($O(nd^2)$). Moreover, this method requires loading the entire matrix to the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Low Rank Approximation\n",
    "**Goal:** Find a method that uses less than $nd^2$ time to output a rank-$k$ matrix $A'$ such that\n",
    "$$\n",
    "\\|A - A'\\|_F \\le (1+\\epsilon)\\|A - A_k\\|_F.\n",
    "$$\n",
    "\n",
    "**Existing literature:**\n",
    "- [Clarkson-Woodruff 13]: near linear time in input sparsity\n",
    "- [Ghashami-Liberty-Phillips-Woodruff 16]: streaming algorithms\n",
    "\n",
    "**Main idea:**\n",
    "- Construct a $k/\\epsilon\\times n$ subspace embedding matrix $S$ (such as CountSketch matrix)\n",
    "- Compute $SA$, which forms a compact representation of rows of $A$.\n",
    "- Project rows of $A$ onto $SA$.\n",
    "- Find the best rank-$k$ approximation to points inside of $SA$. (Since $SA$ is a much smaller matrix, low-rank approximation of $SA$ is much easier to solve.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of embedding matrix $S$\n",
    "\n",
    "**Goal:** $S$ should be easy to construct, and the computation of $SA$ should require less than $ndk$ time.\n",
    "\n",
    "A practical choice is the **CountSketch** matrix, where each column contains exactly one $\\pm 1$ at a random row. For example:\n",
    "\n",
    "\\begin{equation*}\n",
    "S =  \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 1 & 0 & 0 & 1 & 0 & 0\\\\\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & -1& 1 & 0 & -1& 0\\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Because of the special structure of $S$, to compute $SA$,one only need to add $A_{(i)}$ to the result for each row $A_{(i)}$ of matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of low-rank approximation using CountSketch matrix\n",
    "\n",
    "# construct input matrix $A$\n",
    "def input_mat(n, d, r, seed=42):\n",
    "    \"\"\"\n",
    "    Generate an n*d random matrix with approximate rank r.\n",
    "    \n",
    "    Require: n > d > r > 0.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    M = np.random.rand(n, d)\n",
    "    U, S, V = np.linalg.svd(M, full_matrices=False)\n",
    "    diagonal = np.hstack([np.linspace(1, 10, r), np.zeros(d - r)])\n",
    "    new_S = np.diag(diagonal)\n",
    "    return U.dot(new_S).dot(V)\n",
    "\n",
    "n = 200\n",
    "d = 100\n",
    "k = 10\n",
    "A = input_mat(n, d, k)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 200]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: \n",
    "# Generate a CountSketch matrix S, represented by two lists h and sigma, where h stores the row number of \n",
    "# the non-zero entry on each column, and sigma stores its value.\n",
    "def count_sketch(m, n, seed=42):\n",
    "    \"\"\"\n",
    "    Generate an m*n CountSketch matrix\n",
    "    \n",
    "    Output:\n",
    "    size: size of the matrix S\n",
    "    h: a list storing the row number of the non-zero entry on each column\n",
    "    sigma: a list storing the value of the non-zero entry on each column\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    ary = np.arange(m)\n",
    "    size = [m, n]\n",
    "    h = np.random.choice(ary, n)\n",
    "    sigma = np.random.choice([-1, 1], n)\n",
    "    return size, h, sigma\n",
    "    \n",
    "m = 20\n",
    "S_size, S_h, S_sigma = count_sketch(m, n)\n",
    "S_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53440505, -0.23080665,  0.7119568 , ..., -0.63387905,\n",
       "         0.05230352,  0.25924817],\n",
       "       [-0.72076792, -0.20804511,  0.43338964, ...,  0.43135791,\n",
       "         0.12176035,  0.10669987],\n",
       "       [-0.2393303 ,  0.17371414,  0.53481105, ..., -0.22615432,\n",
       "         0.43641781, -0.20194093],\n",
       "       ...,\n",
       "       [-0.33691237, -0.01925639, -0.20071573, ...,  0.64413153,\n",
       "        -0.15210403,  0.26085918],\n",
       "       [ 0.152788  , -0.21561768,  0.53742216, ...,  0.09351726,\n",
       "         0.10495453,  0.3206282 ],\n",
       "       [-0.36520901,  0.2183839 , -0.23870602, ..., -0.92452083,\n",
       "         0.012926  , -0.76878233]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2:\n",
    "# Perform fast matrix multiplication SA.\n",
    "def count_sketch_multi(S_size, S_h, S_sigma, A):\n",
    "    \"\"\"\n",
    "    Multiply S and A.\n",
    "    \"\"\"\n",
    "    m, n = S_size\n",
    "    d = A.shape[1]\n",
    "    result = np.zeros([m, d])\n",
    "    for i in range(n):\n",
    "        result[S_h[i], :] += S_sigma[i] * A[i, :]\n",
    "    return result\n",
    "SA = count_sketch_multi(S_size, S_h, S_sigma, A)\n",
    "SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9094481481462404e-14\n"
     ]
    }
   ],
   "source": [
    "# Step 3:\n",
    "# Project each of the rows onto SA.\n",
    "def approx_embedding(SA, A, m2=None):\n",
    "    \"\"\"\n",
    "    Compute an approximate rank-k embedding X of A onto SA, that is:\n",
    "    a) rank(X) = k\n",
    "    b) X * SA is close to A.\n",
    "    \"\"\"\n",
    "    m, d = SA.shape\n",
    "    \n",
    "    if m2 is None:\n",
    "        m2 = m\n",
    "    R_size, R_h, R_sigma = count_sketch(m2, d)\n",
    "    SAR = count_sketch_multi(R_size, R_h, R_sigma, SA.T).T\n",
    "    AR = count_sketch_multi(R_size, R_h, R_sigma, A.T).T\n",
    "    sol = np.linalg.lstsq(SAR.T, AR.T, rcond=None)\n",
    "    return sol[0].T\n",
    "\n",
    "def exact_embedding(SA, A):\n",
    "    sol = np.linalg.lstsq(SA.T, A.T, rcond=None)\n",
    "    return sol[0].T    \n",
    "\n",
    "X1 = approx_embedding(SA, A)\n",
    "X2 = exact_embedding(SA, A) # for comparison purpose\n",
    "print(np.linalg.norm(X1 - X2)) # X2 should be close to X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0457730711665079e-14\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Find the best rank-k approximation of projected points inside of rowspace SA\n",
    "def low_rank_approx(X, k):\n",
    "    n, d = X.shape\n",
    "    U, S, V = np.linalg.svd(X)\n",
    "    Uk = U[:, :k]\n",
    "    Sigmak = np.diag(S[:k])\n",
    "    Vk = V[:k, :]\n",
    "    return Uk.dot(Sigmak).dot(Vk)\n",
    "X_approx = low_rank_approx(X1, k)\n",
    "print(np.linalg.norm(X1 - X_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low rank approximation error: 9.940630662437842e-14\n",
      "size of A: (200, 100)\n",
      "size of X_approx (200, 20)  | size of SA: (20, 100)\n"
     ]
    }
   ],
   "source": [
    "# Verify that A is closely approximated by the product of X_approx and SA\n",
    "print('Low rank approximation error:', np.linalg.norm(A - X_approx.dot(SA)))\n",
    "print('size of A:', A.shape)\n",
    "print('size of X_approx', X_approx.shape, ' | size of SA:', SA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Problems\n",
    "- **Column subset selection (feature selection, CX, CUR)**: $\\Pi$ consists of columns of $M$. ([Friez-Kannan-Vempala 98], [Drineas-Mahoney-Muthukrishnan 06], [Deshpande-Vempala 06])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Algorithms\n",
    "\n",
    "- Columns arrive one by one\n",
    "- Need to add to $S$ or ignore\n",
    "- Complete with best $S$ in hindsight (in approximation error)\n",
    "\n",
    "**Online PCA:** [Boutsidis-Garber-Karnin-Liberty 15] additive approximation $\\epsilon\\|U\\|_F^2$ using $k\\cdot polylog(n)$ dimensions.\n",
    "\n",
    "**Online CUR:** [Bhaskara 18] $(1+\\epsilon)$ relative error using $k\\cdot polylog(n/\\epsilon)$ columns using adaptive sampling, if a) we have a $poly(n)$ approximation of OPT, and $\\sigma^2_{max}/OPT$ is at most $poly(n, d)$.\n",
    "\n",
    "**Online k-means:** [Meyerson 01] objective: small number of clusters, near-optimal centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing sampling distribution\n",
    "\n",
    "**Assumptions (not essential):**\n",
    "- OPT ($=\\|U - U_k\\|_F$) is known \n",
    "- $\\|U\\|_2$ is known\n",
    "\n",
    "**\"Ideal\" algorithm:**\n",
    "- Select a column with probability proportional to how much it can reduce the objective function:\n",
    "$$\n",
    "p_i := Pr(u_i\\rightarrow S) = \\min\\{1, k\\cdot\\frac{\\|\\Pi_S^\\perp u_i\\|_2^2}{OPT}\\}\n",
    "$$\n",
    "- Difficult to analyze\n",
    "- Observation: it is impossible to have many $p_i$ to be close to 1 (it means $u_i$ has a large component perpendicular to previous chosen columns). Otherwise $U$ is not numerial low rank (Geometric lemma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
